Deleted all the data files in order to simplify repo. While testing the code, all you need is the .pkl file.

For LOPO or LOSO use: rawAudioSegmentedData_window_10_hop_0.5_Test.pkl

For WILD use: WILD....pkl


# This is the README file explaining the organisation of the data set

The data is organised into 15 separate folders for the 15 participants for the semi-naturalistic study, and a zipped folder for the wild data.

## Semi-Naturalistic Data

- The semi-naturalistic data is stored in folders labeled PXX where XX is the participant number from 01-15
  - Each folder contains 2 folders for each session the data was recorded. The label of each session contains the participant number as well. For example session 1 of participant 1 will be labeled 011. For the subsequent explanation participant 1 session will be used as reference
    - In the folder is the raw Motion data labeled as 011.tab
    - The raw Audio data is labeled as 011.wav
    - The annotations extracted as a comma separated file is labeled 011ant.tab
    - The 011.ant file is the custom annotation file generated by our software
    - The Audio and Motion data is segmented according to the annotation into separate files under SegAudio and SegMotion folders respectively
    - Segmented files are labeled as 011a, 011b, etc. where the last letter identifies what activity it is (refer to the paper for alphabetic activity labels). The files labeled as 'x' is the null class extracted as the audio and motion data in between activities.

## Wild Data

- The wild data is organised into folders with a 2 letter unique identifier and a session number. For example HH2.
  - In the folder is the raw Motion data labeled as HH2.csv
    - The raw Audio data is labeled as HH2.mp3
    - The annotations extracted as a comma separated file is labeled HH2_ann.csv
    - The Audio and Motion data is segmented according to the annotation into separate files under SegAudio and SegMotion folders respectively
    - Segmented files are labeled as HH2a___, HH2b___, etc. where the alphabet identifies what activity it is (refer to the paper for alphabetic activity labels). The files labeled as 'x' is the null class extracted as the audio and motion data when no activity was being done. The number after the alphabatic label is to differentiate different segments of the same activity and should be ignored when reading the data.

## Note

- Refer to the github repo for the scripts to segment Audio/Motion data if needed (https://github.com/Human-Signals-Lab/Sound-and-Wrist-Motion-for-Activities-of-Daily-Living-with-Smartwatches.git)
